## Task 1: BIG-DATA-ANALYSIS

---

### üè¢ Internship Details

- **Company**: CODTECH IT SOLUTIONS PVT. LTD.  
- **Name**: ARUN VYAS  
- **Intern ID**: CT12WP97  
- **Domain**: Data Analytics  
- **Internship Duration**: 12 Weeks (March 25, 2025 ‚Äì June 25, 2025)  
- **Mentor**: NEELA SANTOSH KUMAR  

### üìù Task Description

Perform scalable data processing and analysis on a large dataset using Apache Spark (PySpark) to derive actionable insights from real-world data.  
This project demonstrates how distributed computing frameworks can efficiently handle, clean, and analyze datasets exceeding memory limits on traditional machines.

### üõ†Ô∏è Tools & Technologies Used

- **Apache Spark (PySpark)**: Distributed big data processing and analysis  
- **Python**: Programming language  
- **Google Colab**: Interactive coding or batch execution  
- **IEA-EV-data / EV Sales / Historical Cars**: Open large-scale transportation datasets

# üìÇ Files Included
‚Ä¢	Task_1 Big Data Analysis: Main PySpark script for data processing and insights
‚Ä¢	IEA-EV-dataEV salesHistoricalCars: Sample CSV file for small-scale testing

# ‚ñ∂Ô∏è How to Run
1. Install PySpark via pip: pip install pyspark
2. Add Dataset Path
3. Run the PySpark Script:In Google Colab
4. Output will Display

# üì∏ Output Screenshot
![Screenshot 2025-06-12 190242](https://github.com/user-attachments/assets/71f396e5-d1e1-4d9e-9ed0-106326ec88b0)
![Screenshot 2025-06-12 190315](https://github.com/user-attachments/assets/8e252424-f0c1-4394-8e8d-96bbaf1395db)
![Screenshot 2025-06-12 190335](https://github.com/user-attachments/assets/9037b878-1066-428e-b555-787507374da1)
![Screenshot 2025-06-12 190403](https://github.com/user-attachments/assets/5676dd38-5824-4ba9-b941-42bb2d014949)




